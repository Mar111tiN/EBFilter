{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea: ABcache\n",
    "## getting a precomputed ABcache file containing the parameters for beta-binomial distribution from the PoN-list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup arguments and state variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:17.500020Z",
     "start_time": "2019-04-09T19:17:17.054854Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from code import run\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### snakemake config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:17.565628Z",
     "start_time": "2019-04-09T19:17:17.561109Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {'EB':{'run': True}}\n",
    "params = {}\n",
    "params['map_quality'] = 20\n",
    "params['base_quality'] = 15\n",
    "params['filter_flags'] = 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "params['fitting_penalty'] = .5\n",
    "params['caching'] = True\n",
    "# to simulate snakemake behavior\n",
    "config['EB']['threads'] = 1\n",
    "config['EB']['params'] = params\n",
    "config['EB']\n",
    "config['annovar'] = {'sep': '\\t'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the config and global state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:18.127872Z",
     "start_time": "2019-04-09T19:17:18.122126Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from code import run\n",
    "import pandas as pd\n",
    "\n",
    "config = {'EB':{'run': True}}\n",
    "params = {}\n",
    "params['map_quality'] = 20\n",
    "params['base_quality'] = 15\n",
    "params['filter_flags'] = 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "params['fitting_penalty'] = .5\n",
    "params['caching'] = True\n",
    "# to simulate snakemake behavior\n",
    "config['EB']['threads'] = 1\n",
    "config['EB']['params'] = params\n",
    "config['EB']\n",
    "config['annovar'] = {'sep': '\\t'}\n",
    "\n",
    "\n",
    "args = {}\n",
    "params = config['EB']['params']\n",
    "threads = config['EB']['threads']\n",
    "sep = config['annovar']['sep']\n",
    "_q = str(params['map_quality'])  # mapping quality=20\n",
    "_Q = params['base_quality']      # base quality=15\n",
    "fit_pen = params['fitting_penalty']\n",
    "filter_quals = ''\n",
    "for qual in range( 33, 33 + _Q ): \n",
    "    filter_quals += chr( qual )  # qual asciis for filtering out\n",
    "_ff = params['filter_flags']     # 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "state = {'q':_q, 'Q':_Q, 'filter_quals': filter_quals, 'fitting_penalty': fit_pen, 'ff':_ff, 'threads':threads, 'sep': sep}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting my testdata as arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running EBfilter createCache on testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:45:32.058959Z",
     "start_time": "2019-04-10T20:45:31.563559Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from code import run\n",
    "import pandas as pd\n",
    "\n",
    "config = {'EB':{'run': True}}\n",
    "params = {}\n",
    "params['map_quality'] = 20\n",
    "params['base_quality'] = 15\n",
    "params['filter_flags'] = 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "params['fitting_penalty'] = .5\n",
    "params['caching'] = True\n",
    "# to simulate snakemake behavior\n",
    "config['EB']['threads'] = 1\n",
    "config['EB']['params'] = params\n",
    "config['EB']\n",
    "config['annovar'] = {'sep': '\\t'}\n",
    "config['EB']['log'] = 'output/logfile'\n",
    "\n",
    "\n",
    "args = {}\n",
    "params = config['EB']['params']\n",
    "threads = config['EB']['threads']\n",
    "log = config['EB']['log']\n",
    "sep = config['annovar']['sep']\n",
    "_q = str(params['map_quality'])  # mapping quality=20\n",
    "_Q = params['base_quality']      # base quality=15\n",
    "fit_pen = params['fitting_penalty']\n",
    "filter_quals = ''\n",
    "for qual in range( 33, 33 + _Q ): \n",
    "    filter_quals += chr( qual )  # qual asciis for filtering out\n",
    "_ff = params['filter_flags']     # 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "state = {'q':_q, 'Q':_Q, 'filter_quals': filter_quals, 'log':log, 'fitting_penalty': fit_pen, 'ff':_ff, 'threads':threads, 'sep': sep}\n",
    "\n",
    "\n",
    "args['pon_list'] = 'testdata/list_normal_sample.txt'\n",
    "args['cache_path'] = 'output/test.cache'\n",
    "args['generate_cache'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:45:40.515331Z",
     "start_time": "2019-04-10T20:45:32.899711Z"
    }
   },
   "outputs": [],
   "source": [
    "state['threads'] = 3\n",
    "state['debug_mode'] = True\n",
    "run.main(args, state)\n",
    "!ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running EBfilter createCache on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:19.038955Z",
     "start_time": "2019-04-09T19:17:19.035507Z"
    }
   },
   "outputs": [],
   "source": [
    "HOME = os.environ['HOME']\n",
    "args['pon_list'] = f'{HOME}/Dropbox/Icke/Work/somVar/tools/EBFilter/mytestdata/aml_pon.list'\n",
    "args['cache_path'] = f'{HOME}/Dropbox/Icke/Work/somVar/tools/EBFilter/mytestdata/aml_pon.ABcache'\n",
    "args['generate_cache'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running EBfilter in Cache mode on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:10:43.733327Z",
     "start_time": "2019-04-10T18:10:43.626705Z"
    }
   },
   "outputs": [],
   "source": [
    "HOME = os.environ['HOME']\n",
    "args['pon_list'] = f'{HOME}/Dropbox/Icke/Work/somVar/tools/EBFilter/mytestdata/aml_pon.list'\n",
    "args['output_path'] = 'output/test_rel_eb.csv'\n",
    "args['region'] = ''\n",
    "log_file = f\"{os.path.splitext(args['output_path'])[0]}.log\"\n",
    "state['log'] = log_file                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:02:58.134850Z",
     "start_time": "2019-04-10T18:02:58.122259Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from subprocess import Popen, DEVNULL, PIPE\n",
    "state['log'] = 'output/pileup.log'\n",
    "pon_df = pd.read_csv('testdata/list_normal_sample.txt', header=None)\n",
    "pon_sub_folder = 'output/pon'\n",
    "if not os.path.isdir(pon_sub_folder):\n",
    "    os.mkdir(pon_sub_folder)\n",
    "chromosome = 'chr11'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the chromosome list from one of the pon bam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:02:58.887798Z",
     "start_time": "2019-04-10T18:02:58.853018Z"
    }
   },
   "outputs": [],
   "source": [
    "def bam_to_chr_list(bam_file):\n",
    "    bam_stats_cmd = ['samtools', 'idxstats', bam_file]\n",
    "    bam_stats = Popen(bam_stats_cmd, stdout=PIPE, stderr=DEVNULL)\n",
    "    bam_stats_string = StringIO(bam_stats.communicate()[0].decode('utf-8'))\n",
    "    bam_stats_df = pd.read_csv(bam_stats_string, sep='\\t', header=None)\n",
    "    return list(bam_stats_df[0].T)\n",
    "bam_list = bam_to_chr_list(pon_df.iloc[0,0])\n",
    "bam_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split bams for multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:03:04.071720Z",
     "start_time": "2019-04-10T18:02:59.556980Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_bam(chromosome, pon_row):\n",
    "    bam_file = pon_row[0]\n",
    "    bam_out = os.path.join(pon_sub_folder, f\"{os.path.splitext(os.path.basename(bam_file))[0]}_{str(chromosome)}.bam\")\n",
    "    split_bam_cmd = [\"samtools\", \"view\", \"-b\", \"-o\", bam_out, bam_file, str(chromosome)]\n",
    "    bam_index_cmd = [\"samtools\", \"index\", bam_out]\n",
    "    subprocess.check_call(split_bam_cmd)\n",
    "    subprocess.check_call(bam_index_cmd)\n",
    "    return bam_out\n",
    "pon_sub_df = pd.DataFrame()\n",
    "pon_sub_df['bam'] = pon_df.apply(partial(split_bam, chromosome), axis=1)\n",
    "pon_file_sub = os.path.join(pon_sub_folder, f\"pon_list_{chromosome}.txt\")\n",
    "pon_sub_df.to_csv(pon_file_sub, header=None, index=False)\n",
    "pon_count = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the pileup from one of the sub pon_lists (eg. pon_list_chr11.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:03:56.168894Z",
     "start_time": "2019-04-10T18:03:04.159795Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pileup_df(pon_file_sub):\n",
    "    with open(state['log'], 'w+') as log:\n",
    "        mpileup_cmd = [\"samtools\", \"mpileup\", \"-B\", \"-d\", \"10000000\", \"-q\",str(state['q']), \"-Q\",str(state['Q']), \"--ff\",state['ff']]\n",
    "        mpileup_cmd += [\"-b\", pon_file_sub]\n",
    "        pileup_stream = Popen(mpileup_cmd, stdout=PIPE, stderr=log)\n",
    "        pileup_string = StringIO(pileup_stream.communicate()[0].decode('utf-8'))\n",
    "        pileup_stream = Popen(mpileup_cmd, stdout=PIPE, stderr=log)\n",
    "        pileup_string = StringIO(pileup_stream.communicate()[0].decode('utf-8'))\n",
    "        names = ['Chr', 'Start', 'Ref']\n",
    "        for i in range(pon_count):\n",
    "            names += [f\"depth{i}\", f\"read{i}\", f\"Q{i}\"]\n",
    "    return pd.read_csv(pileup_string, sep='\\t', header=None, names=names)\n",
    "pileup_df = get_pileup_df(pon_file_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:05:22.849313Z",
     "start_time": "2019-04-10T18:05:22.842133Z"
    }
   },
   "outputs": [],
   "source": [
    "pileup_small = pileup_df.iloc[:100].copy()\n",
    "pileup_dfs = np.array_split(pileup_small, 3)\n",
    "pileup_dfs[1].iloc[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply a column apply on several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sign_re = re.compile(r'\\^.|\\$')\n",
    "def clean_reads(run_column):\n",
    "\n",
    "    return run_column.str.replace(sign_re, '')\n",
    "\n",
    "\n",
    "pileup_small[['read0', 'read1']] = pileup_small[['read0', 'read1']].apply(lambda column: column.str.replace(sign_re, ''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a new dataframe AB_df with good indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T21:32:34.603022Z",
     "start_time": "2019-04-09T21:32:34.516826Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "AB_df = pileup_small.iloc[:,:2]\n",
    "\n",
    "def getit(var, row):\n",
    "    s = pd.Series(index=[f'{var}+a', f'{var}+b', f'{var}-a', f'{var}-b'])\n",
    "    s = row[['depth1', 'depth2', 'depth3', 'depth4']]\n",
    "    print(row.name)\n",
    "    return s\n",
    "for var in ['A','C','T','G']:\n",
    "    AB_df[[f'{var}+a', f'{var}+b', f'{var}-a',f'{var}-b']] = pileup_small.apply(partial(getit, var), axis=1)\n",
    "AB_df = AB_df.set_index(['Chr', 'Start'])\n",
    "AB_df.columns = columns\n",
    "AB_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
