{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea: ABcache\n",
    "## getting a precomputed ABcache file containing the parameters for beta-binomial distribution from the PoN-list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup arguments and state variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:17.500020Z",
     "start_time": "2019-04-09T19:17:17.054854Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from code import run\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### snakemake config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:17.565628Z",
     "start_time": "2019-04-09T19:17:17.561109Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {'EB':{'run': True}}\n",
    "params = {}\n",
    "params['map_quality'] = 20\n",
    "params['base_quality'] = 15\n",
    "params['filter_flags'] = 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "params['fitting_penalty'] = .5\n",
    "params['caching'] = True\n",
    "# to simulate snakemake behavior\n",
    "config['EB']['threads'] = 1\n",
    "config['EB']['params'] = params\n",
    "config['EB']\n",
    "config['annovar'] = {'sep': '\\t'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the config and global state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:18.127872Z",
     "start_time": "2019-04-09T19:17:18.122126Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from code import run\n",
    "import pandas as pd\n",
    "\n",
    "config = {'EB':{'run': True}}\n",
    "params = {}\n",
    "params['map_quality'] = 20\n",
    "params['base_quality'] = 15\n",
    "params['filter_flags'] = 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "params['fitting_penalty'] = .5\n",
    "params['caching'] = True\n",
    "# to simulate snakemake behavior\n",
    "config['EB']['threads'] = 1\n",
    "config['EB']['params'] = params\n",
    "config['EB']\n",
    "config['annovar'] = {'sep': '\\t'}\n",
    "\n",
    "\n",
    "args = {}\n",
    "params = config['EB']['params']\n",
    "threads = config['EB']['threads']\n",
    "sep = config['annovar']['sep']\n",
    "_q = str(params['map_quality'])  # mapping quality=20\n",
    "_Q = params['base_quality']      # base quality=15\n",
    "fit_pen = params['fitting_penalty']\n",
    "filter_quals = ''\n",
    "for qual in range( 33, 33 + _Q ): \n",
    "    filter_quals += chr( qual )  # qual asciis for filtering out\n",
    "_ff = params['filter_flags']     # 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "state = {'q':_q, 'Q':_Q, 'filter_quals': filter_quals, 'fitting_penalty': fit_pen, 'ff':_ff, 'threads':threads, 'sep': sep}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting my testdata as arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running EBfilter createCache on testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:10:49.583667Z",
     "start_time": "2019-04-10T18:10:49.144747Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from code import run\n",
    "import pandas as pd\n",
    "\n",
    "config = {'EB':{'run': True}}\n",
    "params = {}\n",
    "params['map_quality'] = 20\n",
    "params['base_quality'] = 15\n",
    "params['filter_flags'] = 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "params['fitting_penalty'] = .5\n",
    "params['caching'] = True\n",
    "# to simulate snakemake behavior\n",
    "config['EB']['threads'] = 1\n",
    "config['EB']['params'] = params\n",
    "config['EB']\n",
    "config['annovar'] = {'sep': '\\t'}\n",
    "config['EB']['log'] = 'output/logfile'\n",
    "\n",
    "\n",
    "args = {}\n",
    "params = config['EB']['params']\n",
    "threads = config['EB']['threads']\n",
    "log = config['EB']['log']\n",
    "sep = config['annovar']['sep']\n",
    "_q = str(params['map_quality'])  # mapping quality=20\n",
    "_Q = params['base_quality']      # base quality=15\n",
    "fit_pen = params['fitting_penalty']\n",
    "filter_quals = ''\n",
    "for qual in range( 33, 33 + _Q ): \n",
    "    filter_quals += chr( qual )  # qual asciis for filtering out\n",
    "_ff = params['filter_flags']     # 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "state = {'q':_q, 'Q':_Q, 'filter_quals': filter_quals, 'log':log, 'fitting_penalty': fit_pen, 'ff':_ff, 'threads':threads, 'sep': sep}\n",
    "\n",
    "\n",
    "args['pon_list'] = 'testdata/list_normal_sample.txt'\n",
    "args['cache_path'] = 'output/test.cache'\n",
    "args['generate_cache'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-10T18:10:49.764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Cache...\n",
      "Generating  pileup for chromosome chr4..\n",
      "Generating  pileup for chromosome chr1..\n",
      "Generating  pileup for chromosome chr7..\n",
      "Splitting bam files for chromosome chr4..\n",
      "Splitting bam files for chromosome chr1..\n",
      "Splitting bam files for chromosome chr7..\n",
      "Pileup for chromosome chr1 is empty and will be dropped..\n",
      "Pileup for chromosome chr4 is empty and will be dropped..\n",
      "Pileup for chromosome chr7 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr2..\n",
      "Generating  pileup for chromosome chr5..\n",
      "Generating  pileup for chromosome chr8..\n",
      "Splitting bam files for chromosome chr5..\n",
      "Splitting bam files for chromosome chr8..\n",
      "Splitting bam files for chromosome chr2..\n",
      "Pileup for chromosome chr8 is empty and will be dropped..\n",
      "Pileup for chromosome chr2 is empty and will be dropped..\n",
      "Pileup for chromosome chr5 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr9..\n",
      "Generating  pileup for chromosome chr3..\n",
      "Generating  pileup for chromosome chr6..\n",
      "Splitting bam files for chromosome chr3..\n",
      "Splitting bam files for chromosome chr9..\n",
      "Splitting bam files for chromosome chr6..\n",
      "Pileup for chromosome chr9 is empty and will be dropped..\n",
      "Pileup for chromosome chr6 is empty and will be dropped..\n",
      "Pileup for chromosome chr3 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr10..\n",
      "Generating  pileup for chromosome chr13..\n",
      "Generating  pileup for chromosome chr16..\n",
      "Splitting bam files for chromosome chr16..\n",
      "Splitting bam files for chromosome chr13..\n",
      "Splitting bam files for chromosome chr10..\n",
      "Pileup for chromosome chr10 is empty and will be dropped..\n",
      "Pileup for chromosome chr16 is empty and will be dropped..\n",
      "Pileup for chromosome chr13 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr17..\n",
      "Generating  pileup for chromosome chr11..\n",
      "Generating  pileup for chromosome chr14..\n",
      "Splitting bam files for chromosome chr17..\n",
      "Splitting bam files for chromosome chr11..\n",
      "Splitting bam files for chromosome chr14..\n",
      "Pileup for chromosome chr17 is empty and will be dropped..\n",
      "Pileup for chromosome chr14 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr18..\n",
      "Generating  pileup for chromosome chr15..\n",
      "Splitting bam files for chromosome chr18..\n",
      "Splitting bam files for chromosome chr15..\n",
      "Pileup for chromosome chr18 is empty and will be dropped..\n",
      "Pileup for chromosome chr15 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr19..\n",
      "Generating  pileup for chromosome chr22..\n",
      "Splitting bam files for chromosome chr19..\n",
      "Splitting bam files for chromosome chr22..\n",
      "Pileup for chromosome chr19 is empty and will be dropped..\n",
      "Pileup for chromosome chr22 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr20..\n",
      "Generating  pileup for chromosome chrX..\n",
      "Splitting bam files for chromosome chr20..\n",
      "Splitting bam files for chromosome chrX..\n",
      "Pileup for chromosome chrX is empty and will be dropped..\n",
      "Pileup for chromosome chr20 is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr21..\n",
      "Generating  pileup for chromosome chrY..\n",
      "Splitting bam files for chromosome chr21..\n",
      "Splitting bam files for chromosome chrY..\n",
      "Pileup for chromosome chr21 is empty and will be dropped..\n",
      "Pileup for chromosome chrY is empty and will be dropped..\n",
      "Generating  pileup for chromosome chrM..\n",
      "Splitting bam files for chromosome chrM..\n",
      "Pileup for chromosome chrM is empty and will be dropped..\n",
      "Generating  pileup for chromosome *..\n",
      "Splitting bam files for chromosome *..\n",
      "Pileup for chromosome * is empty and will be dropped..\n",
      "Generating  pileup for chromosome chr12..\n",
      "Splitting bam files for chromosome chr12..\n",
      "Pileup for chromosome chr12 is empty and will be dropped..\n",
      "Process 15160: Computing ABs for chromosome chr11\n",
      "50856 rows to go..\n",
      "Process 15161: Computing ABs for chromosome chr11\n",
      "50856 rows to go..\n",
      "Process 15162: Computing ABs for chromosome chr11\n",
      "50856 rows to go..\n",
      "Process 15160: 0.0% (2000 lines) processed..\n",
      "Process 15161: 0.0% (2000 lines) processed..\n",
      "Process 15162: 0.0% (2000 lines) processed..\n",
      "Process 15160: 0.1% (4000 lines) processed..\n",
      "Process 15161: 0.1% (4000 lines) processed..\n",
      "Process 15162: 0.1% (4000 lines) processed..\n",
      "Process 15160: 0.1% (6000 lines) processed..\n",
      "Process 15161: 0.1% (6000 lines) processed..\n",
      "Process 15162: 0.1% (6000 lines) processed..\n",
      "Process 15160: 0.2% (8000 lines) processed..\n",
      "Process 15161: 0.2% (8000 lines) processed..\n",
      "Process 15162: 0.2% (8000 lines) processed..\n",
      "Process 15160: 0.2% (10000 lines) processed..\n",
      "Process 15161: 0.2% (10000 lines) processed..\n",
      "Process 15162: 0.2% (10000 lines) processed..\n",
      "Process 15160: 0.2% (12000 lines) processed..\n",
      "Process 15161: 0.2% (12000 lines) processed..\n",
      "Process 15162: 0.2% (12000 lines) processed..\n",
      "Process 15160: 0.3% (14000 lines) processed..\n",
      "Process 15161: 0.3% (14000 lines) processed..\n",
      "Process 15162: 0.3% (14000 lines) processed..\n",
      "Process 15160: 0.3% (16000 lines) processed..\n",
      "Process 15161: 0.3% (16000 lines) processed..\n",
      "Process 15162: 0.3% (16000 lines) processed..\n",
      "Process 15160: 0.4% (18000 lines) processed..\n",
      "Process 15161: 0.4% (18000 lines) processed..\n",
      "Process 15162: 0.4% (18000 lines) processed..\n",
      "Process 15160: 0.4% (20000 lines) processed..\n",
      "Process 15161: 0.4% (20000 lines) processed..\n",
      "Process 15162: 0.4% (20000 lines) processed..\n",
      "Process 15160: 0.4% (22000 lines) processed..\n",
      "Process 15161: 0.4% (22000 lines) processed..\n",
      "Process 15162: 0.4% (22000 lines) processed..\n",
      "Process 15160: 0.5% (24000 lines) processed..\n",
      "Process 15161: 0.5% (24000 lines) processed..\n",
      "Process 15162: 0.5% (24000 lines) processed..\n",
      "Process 15160: 0.5% (26000 lines) processed..\n",
      "Process 15161: 0.5% (26000 lines) processed..\n",
      "Process 15162: 0.5% (26000 lines) processed..\n",
      "Process 15160: 0.6% (28000 lines) processed..\n",
      "Process 15161: 0.6% (28000 lines) processed..\n",
      "Process 15162: 0.6% (28000 lines) processed..\n",
      "Process 15160: 0.6% (30000 lines) processed..\n",
      "Process 15161: 0.6% (30000 lines) processed..\n",
      "Process 15162: 0.6% (30000 lines) processed..\n",
      "Process 15160: 0.6% (32000 lines) processed..\n",
      "Process 15161: 0.6% (32000 lines) processed..\n",
      "Process 15162: 0.6% (32000 lines) processed..\n",
      "Process 15160: 0.7% (34000 lines) processed..\n",
      "Process 15161: 0.7% (34000 lines) processed..\n",
      "Process 15162: 0.7% (34000 lines) processed..\n",
      "Process 15160: 0.7% (36000 lines) processed..\n",
      "Process 15161: 0.7% (36000 lines) processed..\n",
      "Process 15162: 0.7% (36000 lines) processed..\n",
      "Process 15160: 0.7% (38000 lines) processed..\n",
      "Process 15161: 0.7% (38000 lines) processed..\n",
      "Process 15162: 0.7% (38000 lines) processed..\n",
      "Process 15160: 0.8% (40000 lines) processed..\n",
      "Process 15161: 0.8% (40000 lines) processed..\n",
      "Process 15162: 0.8% (40000 lines) processed..\n",
      "Process 15160: 0.8% (42000 lines) processed..\n",
      "Process 15161: 0.8% (42000 lines) processed..\n",
      "Process 15162: 0.8% (42000 lines) processed..\n",
      "Process 15160: 0.9% (44000 lines) processed..\n",
      "Process 15161: 0.9% (44000 lines) processed..\n",
      "Process 15162: 0.9% (44000 lines) processed..\n",
      "Process 15160: 0.9% (46000 lines) processed..\n",
      "Process 15161: 0.9% (46000 lines) processed..\n",
      "Process 15162: 0.9% (46000 lines) processed..\n",
      "Process 15160: 0.9% (48000 lines) processed..\n",
      "Process 15161: 0.9% (48000 lines) processed..\n",
      "Process 15162: 0.9% (48000 lines) processed..\n",
      "Process 15160: 1.0% (50000 lines) processed..\n",
      "Process 15161: 1.0% (50000 lines) processed..\n",
      "Process 15162: 1.0% (50000 lines) processed..\n",
      "Process 15160: Computing ABs for chromosome chr11 finished.\n",
      "Process 15160: Computing ABs for chromosome chr11\n",
      "50856 rows to go..\n",
      "Process 15161: Computing ABs for chromosome chr11 finished.\n",
      "Process 15161: Computing ABs for chromosome chr11\n",
      "50856 rows to go..\n",
      "Process 15162: Computing ABs for chromosome chr11 finished.\n",
      "Process 15162: Computing ABs for chromosome chr11\n",
      "50856 rows to go..\n",
      "Process 15160: 0.0% (2000 lines) processed..\n",
      "Process 15161: 0.0% (2000 lines) processed..\n",
      "Process 15162: 0.0% (2000 lines) processed..\n",
      "Process 15160: 0.1% (4000 lines) processed..\n",
      "Process 15161: 0.1% (4000 lines) processed..\n",
      "Process 15162: 0.1% (4000 lines) processed..\n",
      "Process 15160: 0.1% (6000 lines) processed..\n",
      "Process 15161: 0.1% (6000 lines) processed..\n",
      "Process 15162: 0.1% (6000 lines) processed..\n",
      "Process 15160: 0.2% (8000 lines) processed..\n",
      "Process 15161: 0.2% (8000 lines) processed..\n",
      "Process 15162: 0.2% (8000 lines) processed..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 15160: 0.2% (10000 lines) processed..\n",
      "Process 15161: 0.2% (10000 lines) processed..\n",
      "Process 15162: 0.2% (10000 lines) processed..\n",
      "Process 15160: 0.2% (12000 lines) processed..\n",
      "Process 15161: 0.2% (12000 lines) processed..\n",
      "Process 15162: 0.2% (12000 lines) processed..\n",
      "Process 15160: 0.3% (14000 lines) processed..\n",
      "Process 15161: 0.3% (14000 lines) processed..\n",
      "Process 15162: 0.3% (14000 lines) processed..\n",
      "Process 15160: 0.3% (16000 lines) processed..\n",
      "Process 15161: 0.3% (16000 lines) processed..\n",
      "Process 15162: 0.3% (16000 lines) processed..\n",
      "Process 15160: 0.4% (18000 lines) processed..\n",
      "Process 15161: 0.4% (18000 lines) processed..\n",
      "Process 15162: 0.4% (18000 lines) processed..\n",
      "Process 15160: 0.4% (20000 lines) processed..\n",
      "Process 15161: 0.4% (20000 lines) processed..\n",
      "Process 15162: 0.4% (20000 lines) processed..\n",
      "Process 15160: 0.4% (22000 lines) processed..\n",
      "Process 15161: 0.4% (22000 lines) processed..\n",
      "Process 15162: 0.4% (22000 lines) processed..\n",
      "Process 15160: 0.5% (24000 lines) processed..\n",
      "Process 15161: 0.5% (24000 lines) processed..\n",
      "Process 15162: 0.5% (24000 lines) processed..\n",
      "Process 15160: 0.5% (26000 lines) processed..\n",
      "Process 15161: 0.5% (26000 lines) processed..\n",
      "Process 15162: 0.5% (26000 lines) processed..\n",
      "Process 15160: 0.6% (28000 lines) processed..\n",
      "Process 15161: 0.6% (28000 lines) processed..\n",
      "Process 15162: 0.6% (28000 lines) processed..\n",
      "Process 15160: 0.6% (30000 lines) processed..\n",
      "Process 15161: 0.6% (30000 lines) processed..\n",
      "Process 15162: 0.6% (30000 lines) processed..\n",
      "Process 15160: 0.6% (32000 lines) processed..\n",
      "Process 15161: 0.6% (32000 lines) processed..\n",
      "Process 15162: 0.6% (32000 lines) processed..\n",
      "Process 15160: 0.7% (34000 lines) processed..\n",
      "Process 15161: 0.7% (34000 lines) processed..\n",
      "Process 15162: 0.7% (34000 lines) processed..\n",
      "Process 15160: 0.7% (36000 lines) processed..\n",
      "Process 15161: 0.7% (36000 lines) processed..\n",
      "Process 15162: 0.7% (36000 lines) processed..\n",
      "Process 15160: 0.7% (38000 lines) processed..\n",
      "Process 15161: 0.7% (38000 lines) processed..\n",
      "Process 15162: 0.7% (38000 lines) processed..\n",
      "Process 15160: 0.8% (40000 lines) processed..\n",
      "Process 15161: 0.8% (40000 lines) processed..\n",
      "Process 15162: 0.8% (40000 lines) processed..\n",
      "Process 15160: 0.8% (42000 lines) processed..\n",
      "Process 15161: 0.8% (42000 lines) processed..\n",
      "Process 15162: 0.8% (42000 lines) processed..\n",
      "Process 15160: 0.9% (44000 lines) processed..\n",
      "Process 15161: 0.9% (44000 lines) processed..\n",
      "Process 15162: 0.9% (44000 lines) processed..\n",
      "Process 15160: 0.9% (46000 lines) processed..\n",
      "Process 15161: 0.9% (46000 lines) processed..\n",
      "Process 15162: 0.9% (46000 lines) processed..\n",
      "Process 15160: 0.9% (48000 lines) processed..\n",
      "Process 15161: 0.9% (48000 lines) processed..\n",
      "Process 15162: 0.9% (48000 lines) processed..\n",
      "Process 15160: 1.0% (50000 lines) processed..\n",
      "Process 15161: 1.0% (50000 lines) processed..\n",
      "Process 15162: 1.0% (50000 lines) processed..\n",
      "Process 15160: Computing ABs for chromosome chr11 finished.\n",
      "Process 15160: Computing ABs for chromosome chr11\n",
      "50856 rows to go..\n",
      "Process 15161: Computing ABs for chromosome chr11 finished.\n",
      "Process 15161: Computing ABs for chromosome chr11\n",
      "50855 rows to go..\n",
      "Process 15162: Computing ABs for chromosome chr11 finished.\n",
      "Process 15162: Computing ABs for chromosome chr11\n",
      "50855 rows to go..\n",
      "Process 15160: 0.0% (2000 lines) processed..\n",
      "Process 15161: 0.0% (2000 lines) processed..\n",
      "Process 15162: 0.0% (2000 lines) processed..\n",
      "Process 15160: 0.1% (4000 lines) processed..\n",
      "Process 15161: 0.1% (4000 lines) processed..\n",
      "Process 15162: 0.1% (4000 lines) processed..\n",
      "Process 15160: 0.1% (6000 lines) processed..\n",
      "Process 15161: 0.1% (6000 lines) processed..\n",
      "Process 15162: 0.1% (6000 lines) processed..\n",
      "Process 15160: 0.2% (8000 lines) processed..\n",
      "Process 15161: 0.2% (8000 lines) processed..\n",
      "Process 15162: 0.2% (8000 lines) processed..\n",
      "Process 15160: 0.2% (10000 lines) processed..\n",
      "Process 15161: 0.2% (10000 lines) processed..\n",
      "Process 15162: 0.2% (10000 lines) processed..\n",
      "Process 15160: 0.2% (12000 lines) processed..\n",
      "Process 15161: 0.2% (12000 lines) processed..\n",
      "Process 15162: 0.2% (12000 lines) processed..\n",
      "Process 15160: 0.3% (14000 lines) processed..\n",
      "Process 15161: 0.3% (14000 lines) processed..\n",
      "Process 15162: 0.3% (14000 lines) processed..\n",
      "Process 15160: 0.3% (16000 lines) processed..\n",
      "Process 15161: 0.3% (16000 lines) processed..\n",
      "Process 15162: 0.3% (16000 lines) processed..\n",
      "Process 15160: 0.4% (18000 lines) processed..\n",
      "Process 15161: 0.4% (18000 lines) processed..\n",
      "Process 15162: 0.4% (18000 lines) processed..\n",
      "Process 15160: 0.4% (20000 lines) processed..\n",
      "Process 15161: 0.4% (20000 lines) processed..\n",
      "Process 15162: 0.4% (20000 lines) processed..\n",
      "Process 15160: 0.4% (22000 lines) processed..\n",
      "Process 15161: 0.4% (22000 lines) processed..\n",
      "Process 15162: 0.4% (22000 lines) processed..\n",
      "Process 15160: 0.5% (24000 lines) processed..\n",
      "Process 15161: 0.5% (24000 lines) processed..\n",
      "Process 15162: 0.5% (24000 lines) processed..\n",
      "Process 15160: 0.5% (26000 lines) processed..\n",
      "Process 15161: 0.5% (26000 lines) processed..\n",
      "Process 15162: 0.5% (26000 lines) processed..\n",
      "Process 15160: 0.6% (28000 lines) processed..\n",
      "Process 15161: 0.6% (28000 lines) processed..\n",
      "Process 15162: 0.6% (28000 lines) processed..\n",
      "Process 15160: 0.6% (30000 lines) processed..\n",
      "Process 15161: 0.6% (30000 lines) processed..\n",
      "Process 15162: 0.6% (30000 lines) processed..\n",
      "Process 15160: 0.6% (32000 lines) processed..\n",
      "Process 15161: 0.6% (32000 lines) processed..\n"
     ]
    }
   ],
   "source": [
    "state['threads'] = 3\n",
    "state['debug_mode'] = True\n",
    "run.main(args, state)\n",
    "!ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running EBfilter createCache on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-10T19:04:51.721Z"
    }
   },
   "outputs": [],
   "source": [
    "os.path.splitext('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T19:17:19.038955Z",
     "start_time": "2019-04-09T19:17:19.035507Z"
    }
   },
   "outputs": [],
   "source": [
    "HOME = os.environ['HOME']\n",
    "args['pon_list'] = f'{HOME}/Dropbox/Icke/Work/somVar/tools/EBFilter/mytestdata/aml_pon.list'\n",
    "args['cache_path'] = f'{HOME}/Dropbox/Icke/Work/somVar/tools/EBFilter/mytestdata/aml_pon.ABcache'\n",
    "args['generate_cache'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running EBfilter in Cache mode on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:10:43.733327Z",
     "start_time": "2019-04-10T18:10:43.626705Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9fa04dbd2431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHOME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pon_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{HOME}/Dropbox/Icke/Work/somVar/tools/EBFilter/mytestdata/aml_pon.list'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output/test_rel_eb.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'region'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{os.path.splitext(args['output_path'])[0]}.log\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "HOME = os.environ['HOME']\n",
    "args['pon_list'] = f'{HOME}/Dropbox/Icke/Work/somVar/tools/EBFilter/mytestdata/aml_pon.list'\n",
    "args['output_path'] = 'output/test_rel_eb.csv'\n",
    "args['region'] = ''\n",
    "log_file = f\"{os.path.splitext(args['output_path'])[0]}.log\"\n",
    "state['log'] = log_file                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:02:58.134850Z",
     "start_time": "2019-04-10T18:02:58.122259Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from subprocess import Popen, DEVNULL, PIPE\n",
    "state['log'] = 'output/pileup.log'\n",
    "pon_df = pd.read_csv('testdata/list_normal_sample.txt', header=None)\n",
    "pon_sub_folder = 'output/pon'\n",
    "if not os.path.isdir(pon_sub_folder):\n",
    "    os.mkdir(pon_sub_folder)\n",
    "chromosome = 'chr11'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the chromosome list from one of the pon bam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:02:58.887798Z",
     "start_time": "2019-04-10T18:02:58.853018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bam_to_chr_list(bam_file):\n",
    "    bam_stats_cmd = ['samtools', 'idxstats', bam_file]\n",
    "    bam_stats = Popen(bam_stats_cmd, stdout=PIPE, stderr=DEVNULL)\n",
    "    bam_stats_string = StringIO(bam_stats.communicate()[0].decode('utf-8'))\n",
    "    bam_stats_df = pd.read_csv(bam_stats_string, sep='\\t', header=None)\n",
    "    return list(bam_stats_df[0].T)\n",
    "bam_list = bam_to_chr_list(pon_df.iloc[0,0])\n",
    "bam_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split bams for multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:03:04.071720Z",
     "start_time": "2019-04-10T18:02:59.556980Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_bam(chromosome, pon_row):\n",
    "    bam_file = pon_row[0]\n",
    "    bam_out = os.path.join(pon_sub_folder, f\"{os.path.splitext(os.path.basename(bam_file))[0]}_{str(chromosome)}.bam\")\n",
    "    split_bam_cmd = [\"samtools\", \"view\", \"-b\", \"-o\", bam_out, bam_file, str(chromosome)]\n",
    "    bam_index_cmd = [\"samtools\", \"index\", bam_out]\n",
    "    subprocess.check_call(split_bam_cmd)\n",
    "    subprocess.check_call(bam_index_cmd)\n",
    "    return bam_out\n",
    "pon_sub_df = pd.DataFrame()\n",
    "pon_sub_df['bam'] = pon_df.apply(partial(split_bam, chromosome), axis=1)\n",
    "pon_file_sub = os.path.join(pon_sub_folder, f\"pon_list_{chromosome}.txt\")\n",
    "pon_sub_df.to_csv(pon_file_sub, header=None, index=False)\n",
    "pon_count = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the pileup from one of the sub pon_lists (eg. pon_list_chr11.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:03:56.168894Z",
     "start_time": "2019-04-10T18:03:04.159795Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pileup_df(pon_file_sub):\n",
    "    with open(state['log'], 'w+') as log:\n",
    "        mpileup_cmd = [\"samtools\", \"mpileup\", \"-B\", \"-d\", \"10000000\", \"-q\",str(state['q']), \"-Q\",str(state['Q']), \"--ff\",state['ff']]\n",
    "        mpileup_cmd += [\"-b\", pon_file_sub]\n",
    "        pileup_stream = Popen(mpileup_cmd, stdout=PIPE, stderr=log)\n",
    "        pileup_string = StringIO(pileup_stream.communicate()[0].decode('utf-8'))\n",
    "        pileup_stream = Popen(mpileup_cmd, stdout=PIPE, stderr=log)\n",
    "        pileup_string = StringIO(pileup_stream.communicate()[0].decode('utf-8'))\n",
    "        names = ['Chr', 'Start', 'Ref']\n",
    "        for i in range(pon_count):\n",
    "            names += [f\"depth{i}\", f\"read{i}\", f\"Q{i}\"]\n",
    "    return pd.read_csv(pileup_string, sep='\\t', header=None, names=names)\n",
    "pileup_df = get_pileup_df(pon_file_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T18:05:22.849313Z",
     "start_time": "2019-04-10T18:05:22.842133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pileup_small = pileup_df.iloc[:100].copy()\n",
    "pileup_dfs = np.array_split(pileup_small, 3)\n",
    "pileup_dfs[1].iloc[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply a column apply on several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sign_re = re.compile(r'\\^.|\\$')\n",
    "def clean_reads(run_column):\n",
    "\n",
    "    return run_column.str.replace(sign_re, '')\n",
    "\n",
    "\n",
    "pileup_small[['read0', 'read1']] = pileup_small[['read0', 'read1']].apply(lambda column: column.str.replace(sign_re, ''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a new dataframe AB_df with good indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T21:32:34.603022Z",
     "start_time": "2019-04-09T21:32:34.516826Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "AB_df = pileup_small.iloc[:,:2]\n",
    "\n",
    "def getit(var, row):\n",
    "    s = pd.Series(index=[f'{var}+a', f'{var}+b', f'{var}-a', f'{var}-b'])\n",
    "    s = row[['depth1', 'depth2', 'depth3', 'depth4']]\n",
    "    print(row.name)\n",
    "    return s\n",
    "for var in ['A','C','T','G']:\n",
    "    AB_df[[f'{var}+a', f'{var}+b', f'{var}-a',f'{var}-b']] = pileup_small.apply(partial(getit, var), axis=1)\n",
    "AB_df = AB_df.set_index(['Chr', 'Start'])\n",
    "AB_df.columns = columns\n",
    "AB_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
