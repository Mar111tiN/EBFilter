{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the EBfilter by genomon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EBrun (originally EBFilter) is an argparse wrapper passing command line arguments to run.py (is not needed for internal use)\n",
    "* passed arguments:\n",
    "    * targetMutationFile: the .vcf or .anno containing the mutations – needed --> mut_file\n",
    "    * targetBamPath: path to the tumor bam file (+.bai) – needed --> tumor_bam\n",
    "    * controlBamPathList: text list of path to PoN bam files (+ .bai) – needed --> pon_list\n",
    "    * outputPath: clear  – needed --> output_path\n",
    "    * -f option for anno or vcf – not needed --> will be inferred from .ext\n",
    "    * thread_num: –not needed --> taken from config\n",
    "    * -q option for quality threshold – not needed --> default _q config\n",
    "    * -Q option for base quality threshold - not needed --> default _Q from config\n",
    "    * --ff option for filter flags – not needed because of preprocessing??\n",
    "    * --loption for samtools mpileup -l option – must elaborate..\n",
    "    * --region option for restriction of regions on mpileup -l – must elaborate..\n",
    "    * --debug – not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T11:32:55.404519Z",
     "start_time": "2019-03-27T11:32:55.400860Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vcf\n",
    "import pysam\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import math\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so\n",
    "import re\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### snakemake config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T14:01:01.055571Z",
     "start_time": "2019-03-27T14:01:01.051657Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {'EB':{'run': True}}\n",
    "params = {}\n",
    "params['map_quality'] = 20\n",
    "params['base_quality'] = 15\n",
    "params['filter_flags'] = 'UNMAP,SECONDARY,QCFAIL,DUP'\n",
    "params['loption'] = True\n",
    "config['EB']['threads'] = 1\n",
    "config['EB']['params'] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T14:01:02.077449Z",
     "start_time": "2019-03-27T14:01:02.074602Z"
    }
   },
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['mut_file'] = 'testdata/input.anno'\n",
    "args['tumor_bam'] = 'testdata/tumor.bam'\n",
    "args['pon_list'] = 'testdata/list_normal_sample.txt'\n",
    "args['output_path'] = 'output/output.anno'\n",
    "args['region'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T14:01:02.731654Z",
     "start_time": "2019-03-27T14:01:02.725199Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    '''\n",
    "    validates files and refers to respective functions\n",
    "    '''\n",
    "\n",
    "    # should add validity check for arguments\n",
    "    mut_file = args['mut_file']\n",
    "    tumor_bam = args['tumor_bam']\n",
    "    pon_list = args['pon_list']\n",
    "    output_path = args['output_path']\n",
    "    is_anno = not(os.path.splitext(test)[-1] == '.vcf')\n",
    "    region = args['region']\n",
    "\n",
    "    # file existence check\n",
    "    validate(mut_file, tumor_bam, pon_list) \n",
    "    if threads == 1:\n",
    "        # non multi-threading mode\n",
    "        if is_anno:\n",
    "            EBFilter_worker_anno(mut_file, tumor_bam, pon_list, output_path, map_quality, base_qual_thres, filter_flags, is_loption, region, debug_mode)\n",
    "        else: \n",
    "            EBFilter_worker_vcf(mut_file, tumor_bam, pon_list, output_path, map_quality, base_qual_thres, filter_flags, is_loption, region, debug_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the config state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T14:01:04.876397Z",
     "start_time": "2019-03-27T14:01:04.872409Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_mode = True\n",
    "params = config['EB']['params']\n",
    "threads = config['EB']['threads']\n",
    "_q = params['map_quality']\n",
    "_Q = params['base_quality']\n",
    "_ff = params['filter_flags']\n",
    "is_loption = params['loption']\n",
    "log_file = 'output/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### worker_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T14:01:05.959906Z",
     "start_time": "2019-03-27T14:01:05.955786Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-113-e5fdb45c334e>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-113-e5fdb45c334e>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    for line in file_in\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def EBFilter_worker_anno(mut_file, tumor_bam, pon_list, output_path, region):\n",
    "\n",
    "    pon_count = sum(1 for line in open(pon_list, 'r'))\n",
    "\n",
    "    # --> process_anno\n",
    "    if is_loption:\n",
    "        make_region_list(mut_file) # in utils\n",
    "\n",
    "    # generate pileup files\n",
    "    anno2pileup(mut_file, output_path, tumor_bam, region)\n",
    "    anno2pileup(mut_file, output_path, pon_list, region)\n",
    "    ##########\n",
    "\n",
    "    # delete region_list.bed\n",
    "    if is_loption and not debug_mode:\n",
    "        subprocess.check_call([\"rm\", \"-f\", f\"{mut_file}.region_list.bed\"])\n",
    "\n",
    "    ##########\n",
    "    # load pileup files\n",
    "    pos2pileup_target = {}\n",
    "    pos2pileup_control = {}\n",
    "\n",
    "    with open(f\"{output_path}.target.pileup\", 'r') as file_in:\n",
    "        for line in file_in:\n",
    "            field = line.rstrip('\\n').split('\\t')\n",
    "            pos2pileup_target[field[0] + '\\t' + field[1]] = '\\t'.join(field[3:])\n",
    "\n",
    "    with open(f\"{output_path}.control.pileup\", 'r') as file_in:\n",
    "        for line in file_in:\n",
    "            field = line.rstrip('\\n').split('\\t')\n",
    "            pos2pileup_control[field[0] + '\\t' + field[1]] = '\\t'.join(field[3:])\n",
    "    ##########\n",
    "\n",
    "     ##########\n",
    "    # get restricted region if not None\n",
    "    if is_loption and region:\n",
    "        region_match = region_exp.match(region)\n",
    "        reg_chr = region_match.group(1)\n",
    "        reg_start = int(region_match.group(2))\n",
    "        reg_end = int(region_match.group(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_region(region):\n",
    "    '''\n",
    "    returns True if region \n",
    "    '''\n",
    "    region_exp = re.compile('^[^ \\t\\n\\r\\f\\v,]+:\\d+\\-\\d+')\n",
    "    # region format check\n",
    "    if region:\n",
    "        region_match = region_exp.match(region)\n",
    "        if region_match:\n",
    "            return True\n",
    "\n",
    "def validate(mut_file, tumor_bam, pon_list):\n",
    "    # file existence check\n",
    "    if not os.path.exists(mut_file):\n",
    "        sys.stderr.write(f\"No target mutation file: {mut_file}\")\n",
    "        sys.exit(1)\n",
    "    if not os.path.exists(tumor_bam):\n",
    "        sys.stderr.write(f\"No target bam file: {tumor_bam}\")\n",
    "        sys.exit(1)\n",
    "    if not os.path.exists(tumor_bam + \".bai\") and not os.path.exists(re.sub(r'bam$', \"bai\", tumor_bam)):\n",
    "        sys.stderr.write(f\"No index for target bam file: {tumor_bam}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not os.path.exists(pon_list):\n",
    "        sys.stderr.write(f\"No control list file: {pon_list}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    with open(pon_list) as hIN:\n",
    "        for file in hIN:\n",
    "            file = file.rstrip()\n",
    "            if not os.path.exists(file):\n",
    "                sys.stderr.write(f\"No control bam file: {file}\")\n",
    "                sys.exit(1)\n",
    "            if not os.path.exists(file + \".bai\") and not os.path.exists(re.sub(r'bam$', \"bai\", file)):\n",
    "                sys.stderr.write(f\"No index for control bam file: {file}\")\n",
    "                \n",
    "def make_region_list(anno_path):\n",
    "    # make bed file for mpileup\n",
    "    out_path = f\"{anno_path}.region_list.bed\"\n",
    "    with open(anno_path) as file_in:\n",
    "        with open(out_path, 'w') as file_out:\n",
    "            for line in file_in:\n",
    "                field = line.rstrip('\\n').split('\\t')\n",
    "                loc = int(field[1]) - (field[4] == \"-\")  # -1 if field 4 == '-' eg. deletion \n",
    "                print(field[0], (loc - 1), loc, file=file_out, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    '''\n",
    "    validates files and refers to respective functions\n",
    "    '''\n",
    "\n",
    "    # should add validity check for arguments\n",
    "    mut_file = args['mut_file']\n",
    "    tumor_bam = args['tumor_bam']\n",
    "    pon_list = args['pon_list']\n",
    "    output_path = args['output_path']\n",
    "    is_anno = not(os.path.splitext(mut_file)[-1] == '.vcf')\n",
    "    region = args['region']\n",
    "\n",
    "    # file existence check\n",
    "    validate(mut_file, tumor_bam, pon_list) \n",
    "    if threads == 1:\n",
    "        # non multi-threading mode\n",
    "        if is_anno:\n",
    "            EBFilter_worker_anno(mut_file, tumor_bam, pon_list, output_path, region)\n",
    "        else: \n",
    "            EBFilter_worker_vcf(mut_file, tumor_bam, pon_list, output_path, region)\n",
    "    else:\n",
    "        # multi-threading mode\n",
    "        ##########\n",
    "\n",
    "        if is_anno:\n",
    "            # partition anno files\n",
    "            partition_anno(mut_file, output_path, threads)\n",
    "\n",
    "            jobs = []\n",
    "\n",
    "            for i in range(threads):\n",
    "                worker_args = (f\"{output_path}.{i}\", tumor_bam, pon_list, f\"{output_path}.{i}\", region)\n",
    "                process = multiprocessing.Process(target=EBFilter_worker_anno, args=worker_args)\n",
    "                    \n",
    "                jobs.append(process)\n",
    "                process.start()\n",
    "        \n",
    "            # wait all the jobs to be done\n",
    "            for i in range(threads):\n",
    "                jobs[i].join()\n",
    "        \n",
    "            # merge the individual results\n",
    "            merge_anno(output_path, threads)\n",
    "        \n",
    "            # delete intermediate files\n",
    "            if debug_mode == False:\n",
    "                for i in range(threads):\n",
    "                    subprocess.check_call([\"rm\", f\"{output_path}.{i}\", f\"{output_path}.{i}.control.pileup\", f\"{output_path}.{i}.target.pileup\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anno2pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anno2pileup(anno_path, out_path, bam_or_pon, region):\n",
    "    '''\n",
    "    creates a pileup from all the entries in the anno file\n",
    "    '''\n",
    "    with open(log_file, 'w') as log:\n",
    "        with open(anno_path, 'r') as file_in:\n",
    "            with open(out_path, 'w') as file_out:\n",
    "                mpileup_cmd = [\"samtools\", \"mpileup\", \"-B\", \"-d\", \"10000000\", \"-q\", _q, \"-Q\", _Q, \"--ff\", _ff]\n",
    "\n",
    "                # add tumor_bam or pon_list of bam files depending on file extension of bam_or_pon\n",
    "                if (os.path.splitext(bam_or_pon)[-1] == '.bam'):\n",
    "                    mpileup_cmd += [bam_or_pon]\n",
    "                else:\n",
    "                    mpileup_cmd += [\"-b\", bam_or_pon]\n",
    "\n",
    "                if is_loption:\n",
    "                    # region_list.bed is generated by worker_anno\n",
    "                    mpileup_cmd += [\"-l\", f\"{anno_path}.region_list.bed\"]\n",
    "\n",
    "                    if region:\n",
    "                        mpileup_cmd = mpileup_cmd + [\"-r\", region]\n",
    "                    subprocess.check_call([str(command) for command in mpileup_cmd], stdout=file_out, stderr=log) # maybe logging\n",
    "                # no loption \n",
    "                else: \n",
    "                    # get lines of anno file\n",
    "                    for line in file_in:\n",
    "                        print('anno2pileup', line, bam_or_pon)\n",
    "                        field = line.rstrip('\\n').split('\\t')\n",
    "                        loc = int(field[1]) - (field[4] == \"-\") # -1 if field 4 == '-' eg. deletion\n",
    "                        mutReg = f\"{field[0]}:{loc}-{loc}\"\n",
    "                \n",
    "                        # set region for mpileup\n",
    "                        mpileup_cmd += [\"-r\", mutReg]\n",
    "                        subprocess.check_call([str(command) for command in mpileup_cmd], stdout=file_out, stderr=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 1\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs                          output.anno.2.control.pileup\r\n",
      "output.anno                   output.anno.2.target.pileup\r\n",
      "output.anno.0.control.pileup  output.anno.control.pileup\r\n",
      "output.anno.0.target.pileup   output.anno.sub.anno.1\r\n",
      "output.anno.1.control.pileup  output.anno.sub.anno.2\r\n",
      "output.anno.1.target.pileup   output.anno.target.pileup\r\n"
     ]
    }
   ],
   "source": [
    "ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_anno(anno_path, out_path, threads):\n",
    "\n",
    "    \n",
    "    with open(anno_path, 'r') as file_in:\n",
    "        # get line number\n",
    "        record_num = sum(1 for line in file_in)\n",
    "        file_in.seek(0,0)\n",
    "        threads = min(record_num, threads)\n",
    "        # get lines per subprocess\n",
    "        frac_lines = record_num / threads\n",
    "\n",
    "        current_sub = current_line = 0\n",
    "        file_out = open(f\"{out_path}.{current_sub}\", 'w')\n",
    "        for line in file_in:\n",
    "            print(line.rstrip(\"\\n\"), file=file_out) \n",
    "            current_line += 1\n",
    "            if (current_line >= frac_lines) and (current_sub < threads - 1):\n",
    "                current_sub += 1\n",
    "                current_line = 0\n",
    "                file_out.close()\n",
    "                file_out = open(f\"{out_path}.{current_sub}\", 'w')\n",
    "        file_out.close()\n",
    "\n",
    "    return threads\n",
    "\n",
    "\n",
    "def merge_anno(out_path, threads):\n",
    "\n",
    "    file_out = open(out_path, 'w')\n",
    "    for i in range(threads):\n",
    "        file_in = open(f\"{out_path}.{i}\", 'r')\n",
    "        for line in file_in:\n",
    "            print(line.rstrip('\\n'), file=file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 3\n",
    "debug_mode = False\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs         output.anno\r\n"
     ]
    }
   ],
   "source": [
    "ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpileup = pd.read_csv('output/tumor.mpileup', sep='\\t', header=None, names=['Chr', 'Start', 'ref', 'depth', 'reads', 'mapQ'], dtype={'Start':int, 'reads':str, 'mapQ': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chr</th>\n",
       "      <th>Start</th>\n",
       "      <th>ref</th>\n",
       "      <th>depth</th>\n",
       "      <th>reads</th>\n",
       "      <th>mapQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>chr11</td>\n",
       "      <td>193069</td>\n",
       "      <td>N</td>\n",
       "      <td>40</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCccCCCccCccCCCCCcCC</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Chr   Start ref  depth                                     reads  \\\n",
       "290  chr11  193069   N     40  CCCCCCCCCCCCCCCCCCCCCCccCCCccCccCCCCCcCC   \n",
       "\n",
       "                                         mapQ  \n",
       "290  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpileup[mpileup['Start'] == 193069]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fast/users/szyskam_c/work/miniconda/envs/EB-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
